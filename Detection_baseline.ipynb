{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Detection_baseline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPTGsp2Ues0d4adD4xit+37",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndrewTrefilov/solution-participants-AITrain/blob/master/Detection_baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9zaSfEUblpl"
      },
      "source": [
        "<h1 align=\"center\">Detection Baseline</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBLB16nNbUuY"
      },
      "source": [
        "![](https://habrastorage.org/webt/mi/ca/_c/mica_cm-rdj8z3rrztfk4a-k3_q.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7vqTdoad3z3"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lurvgc6sZhOs"
      },
      "source": [
        "> **–ó–ê–î–ê–ß–ê:** –ù–∞ –æ—Å–Ω–æ–≤–µ —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —Å–æ–∑–¥–∞—Ç—å –∞–ª–≥–æ—Ä–∏—Ç–º –¥–µ—Ç–µ–∫—Ü–∏–∏ —Å–ª–µ–¥—É—é—â–∏—Ö –æ–±—ä–µ–∫—Ç–æ–≤: `'Car', 'Human', 'Wagon', 'FacingSwitchL', 'FacingSwitchR', 'FacingSwitchNV', 'TrailingSwitchL', 'TrailingSwitchR', 'TrailingSwitchNV', 'SignalE', 'SignalF'`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2zWVpEJd5Ai"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8RlhId_zD1s"
      },
      "source": [
        "<h1 align=\"center\">–û–≥–ª–∞–≤–ª–µ–Ω–∏–µ</h1>\n",
        "\n",
        "- [1. Train/val/test split](#part1) <br>\n",
        "- [2. –ü–æ–¥–≥–æ—Ç–æ–≤–∏–º –¥–∞—Ç–∞—Å–µ—Ç](#part2) <br>\n",
        "    - [2.1 –û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π](#part2.1) <br>\n",
        "    - [2.2 –°–æ–∑–¥–∞–¥–∏–º —Ñ–∞–π–ª —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º –¥–∞—Ç–∞—Å–µ—Ç–æ–≤](#part2.2) <br>\n",
        "    - [2.3 –ü–æ–¥–≥–æ—Ç–æ–≤–∏–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ —Ä–∞–∑–º–µ—Ç–∫—É](#part2.3) <br>\n",
        "- [3. –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏](#part3) <br>\n",
        "- [4. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏](#part4) <br>\n",
        "- [5. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏](#part5) <br>\n",
        "- [6. –û—Ü–µ–Ω–∏–≤–∞–Ω–∏–µ](#part5) <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2LvsTpBzDsC"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nC3H__XsdkIZ"
      },
      "source": [
        "<h1 align=\"center\">0. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ –∏–º–ø–æ—Ä—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmEGckFvdoqw"
      },
      "source": [
        "> **NOTE**: –í –∫–∞—á–µ—Å—Ç–≤–µ –±–µ–π–∑–ª–∞–π–Ω–∞ –≤—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å yolov5, –æ–±—É—á–∞—Ç—å –º–æ–¥–µ–ª—å –±—É–¥–µ–º —á–µ—Ä–µ–∑ –∫–æ–º–∞–Ω–¥–Ω—É—é —Å—Ç—Ä–æ–∫—É"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUza-GCCB3XL"
      },
      "source": [
        "!git clone https://github.com/ultralytics/yolov5.git > /dev/null\n",
        "!cd yolov5 && pip install -r requirements.txt > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdSfgZVBGCmW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd07bae3-fe3a-40b4-b6db-a2c5298a8cd2"
      },
      "source": [
        "import os\n",
        "import yaml\n",
        "from PIL import Image\n",
        "import random\n",
        "import numpy as np\n",
        "from shutil import copyfile\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "\n",
        "# https://github.com/AndrewTrefilov/solution-participants-AITrain\n",
        "from detection.helpers import makedirs, get_yolo_labels, copy_images"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzGZYspoF5_k"
      },
      "source": [
        "<a id='part1'></a>\n",
        "<h1 align=\"center\">1. Train/val/test split</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2nomPRNCbv7"
      },
      "source": [
        "# !cp ../gdrive/MyDrive/AIJ-2021/input/AITrain_train.zip ./\n",
        "# !unzip -q AITrain_train.zip"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkaWTyu0wBld"
      },
      "source": [
        "PATH_TO_BBOXES = 'train_data/bboxes'\n",
        "PATH_TO_IMAGES = 'train_data/images'\n",
        "PATH_TO_SAVE_LABELS = 'train_data/labels'\n",
        "\n",
        "CLASS_NAMES = ['Car', 'Human', 'Wagon', 'FacingSwitchL', 'FacingSwitchR', 'FacingSwitchNV', 'TrailingSwitchL', 'TrailingSwitchR', 'TrailingSwitchNV', 'SignalE', 'SignalF']"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmpI3QJXFgPp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91e48857-38b2-45a8-aa79-95d5e9567506"
      },
      "source": [
        "random.seed(0)\n",
        "IMAGES_NAME = os.listdir(PATH_TO_IMAGES)\n",
        "random.shuffle(IMAGES_NAME)\n",
        "\n",
        "train_images = IMAGES_NAME[:int(len(IMAGES_NAME)*0.7)]\n",
        "val_images = IMAGES_NAME[int(len(IMAGES_NAME)*0.7): int(len(IMAGES_NAME)*0.85)]\n",
        "test_images = IMAGES_NAME[int(len(IMAGES_NAME)*0.85):]\n",
        "len(train_images), len(val_images), len(test_images)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5742, 1230, 1231)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GF20X4t2Xldo"
      },
      "source": [
        "DATASET_TYPE2IMAGE = {'train': train_images,\n",
        "                      'val': val_images,\n",
        "                      'test': test_images}\n",
        "\n",
        "IMAGE2DATASET_TYPE = {}\n",
        "for key, values in DATASET_TYPE2IMAGE.items():\n",
        "    for file_name in values:\n",
        "        IMAGE2DATASET_TYPE[file_name] = key"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpdWB-jQHvzK"
      },
      "source": [
        "<a id='part2'></a>\n",
        "<h1 align=\"center\">2. –ü–æ–¥–≥–æ—Ç–æ–≤–∏–º –¥–∞—Ç–∞—Å–µ—Ç</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxO5tILefqv2"
      },
      "source": [
        "<a id='part2.1'></a>\n",
        "<h2 align=\"center\">2.1 –û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJYZVSlyolET"
      },
      "source": [
        "–î–∞–Ω–Ω—ã–µ - –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ —Ä–∞–∑–º–µ—Ç–∫–∞ –¥–ª—è **train**, **val** –∏ **test** –≤—ã–±–æ—Ä–æ–∫, –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ—Ä–≥–∞–Ω–∏–∑–æ–≤–∞–Ω—ã –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å –ø—Ä–∏–≤–µ–¥–µ–Ω–Ω—ã–º –Ω–∏–∂–µ –ø—Ä–∏–º–µ—Ä–æ–º.  \n",
        "YOLOv5 –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞—Ö–æ–¥–∏—Ç —Ä–∞–∑–º–µ—Ç–∫—É –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –∑–∞–º–µ–Ω—è—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é */ images /* –≤ –∫–∞–∂–¥–æ–º –ø—É—Ç–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ */ labels /*. \n",
        "–ù–∞–ø—Ä–∏–º–µ—Ä:  \n",
        "`train_data/images/train/0.jpg  # image`  \n",
        "`train_data/labels/train/0.txt  # label`  \n",
        "   \n",
        "---\n",
        "  \n",
        "*(–ü–æ—ç—Ç–æ–º—É –≤ —Ñ–∞–π–ª–µ —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —É–∫–∞–∑–∞—Ç—å —Ç–æ–ª—å–∫–æ –ø—É—Ç—å –¥–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏, –Ω–∞–ø—Ä–∏–º–µ—Ä –¥–ª—è **train** –≤—ã–±–æ—Ä–∫–∏ `train_data/images/train/`)*\n",
        "\n",
        "\n",
        "```\n",
        "train_data\n",
        "‚îú‚îÄ‚îÄ images\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ test\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ train\n",
        "‚îÇ   ‚îî‚îÄ‚îÄ val\n",
        "‚îî‚îÄ‚îÄ labels\n",
        "    ‚îú‚îÄ‚îÄ test\n",
        "    ‚îú‚îÄ‚îÄ train\n",
        "    ‚îî‚îÄ‚îÄ val\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egflHhxuossD"
      },
      "source": [
        "<a id='part2.2'></a>\n",
        "<h2 align=\"center\">2.2 –°–æ–∑–¥–∞–¥–∏–º —Ñ–∞–π–ª —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º –¥–∞—Ç–∞—Å–µ—Ç–æ–≤</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1OLwnOfgvdq"
      },
      "source": [
        "```\n",
        "# –ü—É—Ç–∏ –¥–æ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ (–¥–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏)\n",
        "train: ../train_data/images/train/\n",
        "val: ../train_data/images/val/\n",
        "test: ../train_data/images/test/\n",
        "\n",
        "# –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤\n",
        "nc: 11\n",
        "\n",
        "# –ù–∞–∑–≤–∞–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤\n",
        "names: ['Car', 'Human', 'Wagon', 'FacingSwitchL', 'FacingSwitchR', 'FacingSwitchNV', 'TrailingSwitchL', 'TrailingSwitchR', 'TrailingSwitchNV', 'SignalE', 'SignalF']\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMl3ZQQO4Ler"
      },
      "source": [
        "aitrain_dataset = [\"train: ../train_data/images/train/\" + \"\\n\",\n",
        "                 \"val: ../train_data/images/val/\" + \"\\n\",\n",
        "                 \"test: ../train_data/images/test/\" + \"\\n\\n\",\n",
        "                 \"nc: 11\" + \"\\n\\n\",\n",
        "                 \"names: ['Car', 'Human', 'Wagon', 'FacingSwitchL', 'FacingSwitchR', 'FacingSwitchNV', 'TrailingSwitchL', 'TrailingSwitchR', 'TrailingSwitchNV', 'SignalE', 'SignalF']\",\n",
        "                ]\n",
        "\n",
        "with open(r'yolov5/data/aitrain_dataset.yaml', 'w') as f:\n",
        "    f.writelines(aitrain_dataset)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YngudpHMIzs4"
      },
      "source": [
        "<a id='part2.3'></a>\n",
        "<h2 align=\"center\">2.3 –ü–æ–¥–≥–æ—Ç–æ–≤–∏–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ —Ä–∞–∑–º–µ—Ç–∫—É</h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouWbzkFxoKvZ"
      },
      "source": [
        "# –°–æ–∑–¥–∞–¥–∏–º –Ω—É–∂–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏\n",
        "makedirs(PATH_TO_SAVE_LABELS, PATH_TO_IMAGES, DATASET_TYPE2IMAGE)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qulBykmrnZL"
      },
      "source": [
        "# –°–æ–∑–¥–∞–¥–∏–º –∏ —Å–æ—Ö—Ä–∞–Ω–∏–º —Ä–∞–∑–º–µ—Ç–∫—É\n",
        "get_yolo_labels(PATH_TO_BBOXES, PATH_TO_SAVE_LABELS, PATH_TO_IMAGES, IMAGE2DATASET_TYPE, CLASS_NAMES)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7jIegiWr9c0",
        "outputId": "fe965f17-0799-443a-a909-59447718cf19"
      },
      "source": [
        "# –°–∫–æ–ø–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
        "copy_images(IMAGES_NAME, IMAGE2DATASET_TYPE, PATH_TO_IMAGES)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8203/8203 [03:52<00:00, 35.31it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXkPpuKXfx2N"
      },
      "source": [
        "<a id='part3'></a>\n",
        "<h1 align=\"center\">3. –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-c0nBQ1hgYoZ"
      },
      "source": [
        "–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å, —Å –∫–æ—Ç–æ—Ä–æ–π –º–æ–∂–Ω–æ –Ω–∞—á–∞—Ç—å –æ–±—É—á–µ–Ω–∏–µ.\n",
        "–ü—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –≤–µ—Å–∞ –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏.\n",
        "–ü–æ–¥—Ä–æ–±–Ω–µ–µ –ø–æ [—Å—Å—ã–ª–∫–µ](https://github.com/ultralytics/yolov5#pretrained-checkpoints)\n",
        "![](https://habrastorage.org/webt/qk/as/y_/qkasy_mlt0kkcih7d7z2wk6li6g.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFSi2WpUgfbb"
      },
      "source": [
        "<a id='part4'></a>\n",
        "<h1 align=\"center\">4. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWGjkwHITMtC"
      },
      "source": [
        "–ü–æ –ø—É—Ç–∏ `yolov5/data/hyps/hyp.scratch.yaml` - –Ω–∞—Ö–æ–¥–∏—Ç—Å—è —Ñ–∞–π–ª —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.\n",
        "\n",
        "–ü–æ—Å–∫–æ–ª—å–∫—É —É –Ω–∞—Å –≤ –∑–∞–¥–∞—á–µ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–ª–∞—Å—Å—ã, –∑–∞–≤–∏—Å—è—â–∏–µ –æ—Ç –ª–µ–≤–æ–π –∏ –ø—Ä–∞–≤–æ–π —Å—Ç–æ—Ä–æ–Ω—ã, –ø–æ—Å—Ç–∞–≤–∏–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –¥–ª—è –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ fliplr —Ä–∞–≤–Ω–æ–π –Ω—É–ª—é:\n",
        "`fliplr: 0.0  # image flip left-right (probability)` , —Å–æ–∑–¥–∞–¥–∏–º –Ω–æ–≤—ã–π —Ñ–∞–π–ª - `yolov5/data/hyps/hyp_aitrain.yaml`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpEnyeXKUXUJ"
      },
      "source": [
        "with open(\"yolov5/data/hyps/hyp.scratch.yaml\", \"r\") as f:\n",
        "    hyps = yaml.safe_load(f)\n",
        "\n",
        "hyps['fliplr'] = 0.0\n",
        "\n",
        "with open(\"yolov5/data/hyps/hyp_aitrain.yaml\", 'w') as f:\n",
        "    yaml.dump(hyps, f)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ys5CK63H4svR",
        "outputId": "1a776f85-511a-4d63-e2e7-d95dca07cb76"
      },
      "source": [
        " # Train YOLOv5m6 on train_dataset for 30 epochs\n",
        "!cd yolov5 && python train.py --img 1280 --batch 8 --epochs 30 --data aitrain_dataset.yaml --weights yolov5m6.pt --hyp data/hyps/hyp_aitrain.yaml --name exp6"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5m6.pt, cfg=, data=aitrain_dataset.yaml, hyp=data/hyps/hyp_aitrain.yaml, epochs=30, batch_size=8, imgsz=1280, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, entity=None, project=runs/train, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias=latest, local_rank=-1, freeze=0, patience=100\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ‚úÖ\n",
            "YOLOv5 üöÄ v5.0-492-gb0ade48 torch 1.9.0+cu102 CUDA:0 (Tesla P100-PCIE-16GB, 16280.875MB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0manchor_t=4.0, box=0.05, cls=0.5, cls_pw=1.0, copy_paste=0.0, degrees=0.0, fl_gamma=0.0, fliplr=0.0, flipud=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, iou_t=0.2, lr0=0.01, lrf=0.2, mixup=0.0, momentum=0.937, mosaic=1.0, obj=1.0, obj_pw=1.0, perspective=0.0, scale=0.5, shear=0.0, translate=0.1, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005\n",
            "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 üöÄ runs (RECOMMENDED)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Overriding model.yaml nc=80 with nc=11\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      5280  models.common.Focus                     [3, 48, 3]                    \n",
            "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
            "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
            "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
            "  4                -1  6    629760  models.common.C3                        [192, 192, 6]                 \n",
            "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
            "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
            "  7                -1  1   1991808  models.common.Conv                      [384, 576, 3, 2]              \n",
            "  8                -1  2   2327040  models.common.C3                        [576, 576, 2]                 \n",
            "  9                -1  1   3982848  models.common.Conv                      [576, 768, 3, 2]              \n",
            " 10                -1  1   1476864  models.common.SPP                       [768, 768, [3, 5, 7]]         \n",
            " 11                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
            " 12                -1  1    443520  models.common.Conv                      [768, 576, 1, 1]              \n",
            " 13                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 14           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
            " 15                -1  2   2658816  models.common.C3                        [1152, 576, 2, False]         \n",
            " 16                -1  1    221952  models.common.Conv                      [576, 384, 1, 1]              \n",
            " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 18           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 19                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
            " 20                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
            " 21                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 22           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
            " 24                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
            " 25          [-1, 20]  1         0  models.common.Concat                    [1]                           \n",
            " 26                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
            " 27                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
            " 28          [-1, 16]  1         0  models.common.Concat                    [1]                           \n",
            " 29                -1  2   2437632  models.common.C3                        [768, 576, 2, False]          \n",
            " 30                -1  1   2987136  models.common.Conv                      [576, 576, 3, 2]              \n",
            " 31          [-1, 12]  1         0  models.common.Concat                    [1]                           \n",
            " 32                -1  2   4429824  models.common.C3                        [1152, 768, 2, False]         \n",
            " 33  [23, 26, 29, 32]  1     92352  models.yolo.Detect                      [11, [[19, 27, 44, 40, 38, 94], [96, 68, 86, 152, 180, 137], [140, 301, 303, 264, 238, 542], [436, 615, 739, 380, 925, 792]], [192, 384, 576, 768]]\n",
            "Model Summary: 503 layers, 35518752 parameters, 35518752 gradients, 51.6 GFLOPs\n",
            "\n",
            "Transferred 644/652 items from yolov5m6.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 107 weight, 111 weight (no decay), 111 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../train_data/labels/train.cache' images and labels... 5742 found, 0 missing, 737 empty, 1 corrupted: 100% 5742/5742 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label ../train_data/images/train/img_0.4362268919113308.png: duplicate labels\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '../train_data/labels/val.cache' images and labels... 1230 found, 0 missing, 155 empty, 0 corrupted: 100% 1230/1230 [00:00<?, ?it/s]\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "Plotting labels... \n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 2.34, Best Possible Recall (BPR) = 0.8132. Attempting to improve anchors, please wait...\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mWARNING: Extremely small objects found. 937 of 31864 labels are < 3 pixels in size.\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 12 anchors on 31842 points...\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 0.9986 best possible recall, 5.34 anchors past thr\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=12, img_size=1280, metric_all=0.274/0.729-mean/best, past_thr=0.476-mean: 6,6,  11,15,  22,10,  37,16,  21,29,  58,26,  41,53,  93,45,  84,109,  155,77,  225,182,  374,368\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.7555: 100% 1000/1000 [00:11<00:00, 86.42it/s]\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 0.9997 best possible recall, 6.01 anchors past thr\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=12, img_size=1280, metric_all=0.302/0.755-mean/best, past_thr=0.484-mean: 4,5,  7,9,  19,7,  12,16,  25,12,  39,16,  25,29,  51,26,  72,38,  109,61,  171,124,  301,285\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
            "\n",
            "Image sizes 1280 train, 1280 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp6\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      0/29     11.5G    0.1112   0.03631   0.03981        34      1280: 100% 718/718 [32:00<00:00,  2.67s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 77/77 [02:02<00:00,  1.60s/it]\n",
            "                 all       1230       6912      0.115      0.258       0.11     0.0292\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      1/29     12.3G   0.09206   0.03044   0.02196        51      1280: 100% 718/718 [32:19<00:00,  2.70s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 77/77 [01:58<00:00,  1.54s/it]\n",
            "                 all       1230       6912      0.269      0.262      0.163      0.049\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      2/29     12.3G   0.08766   0.03103   0.01871        34      1280: 100% 718/718 [31:56<00:00,  2.67s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 77/77 [01:57<00:00,  1.52s/it]\n",
            "                 all       1230       6912      0.237      0.278      0.193     0.0572\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      3/29     12.3G   0.08304   0.03108   0.01648        36      1280: 100% 718/718 [31:36<00:00,  2.64s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 77/77 [01:59<00:00,  1.55s/it]\n",
            "                 all       1230       6912      0.302      0.398      0.274     0.0957\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      4/29     12.3G   0.07799   0.03039   0.01457        40      1280: 100% 718/718 [31:39<00:00,  2.65s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 77/77 [01:59<00:00,  1.56s/it]\n",
            "                 all       1230       6912      0.362      0.392      0.312      0.113\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      5/29     12.3G   0.07474   0.03008   0.01315        39      1280: 100% 718/718 [31:58<00:00,  2.67s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 77/77 [01:59<00:00,  1.55s/it]\n",
            "                 all       1230       6912      0.373      0.391      0.315      0.112\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      6/29     12.3G   0.07332    0.0297   0.01236        45      1280: 100% 718/718 [32:18<00:00,  2.70s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 77/77 [01:58<00:00,  1.55s/it]\n",
            "                 all       1230       6912      0.412        0.4      0.358      0.131\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      7/29     12.3G    0.0708   0.02873   0.01182        49      1280: 100% 718/718 [32:13<00:00,  2.69s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 77/77 [02:00<00:00,  1.57s/it]\n",
            "                 all       1230       6912       0.43       0.45      0.389      0.145\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      8/29     12.3G    0.0694   0.02865   0.01074        52      1280: 100% 718/718 [32:07<00:00,  2.68s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 77/77 [01:59<00:00,  1.55s/it]\n",
            "                 all       1230       6912      0.449      0.444      0.398      0.153\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      9/29     12.3G   0.06788   0.02801   0.01005        59      1280: 100% 718/718 [32:06<00:00,  2.68s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 77/77 [02:00<00:00,  1.57s/it]\n",
            "                 all       1230       6912       0.46       0.47      0.414      0.156\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     10/29     12.3G   0.06686   0.02778   0.00918        75      1280: 100% 718/718 [32:35<00:00,  2.72s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 77/77 [02:02<00:00,  1.58s/it]\n",
            "                 all       1230       6912      0.438      0.522      0.421      0.163\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     11/29     12.3G   0.06572   0.02727  0.009082        24      1280: 100% 718/718 [32:12<00:00,  2.69s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 77/77 [01:58<00:00,  1.54s/it]\n",
            "                 all       1230       6912        0.5      0.469      0.439      0.169\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     12/29     12.3G   0.06502   0.02737  0.008515        39      1280: 100% 718/718 [31:15<00:00,  2.61s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 77/77 [01:55<00:00,  1.50s/it]\n",
            "                 all       1230       6912       0.51      0.489      0.449      0.178\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     13/29     12.3G   0.06335   0.02647  0.008262        33      1280: 100% 718/718 [31:07<00:00,  2.60s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 77/77 [01:55<00:00,  1.50s/it]\n",
            "                 all       1230       6912      0.494      0.485      0.441      0.175\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     14/29     12.3G   0.06275   0.02629  0.007858        56      1280: 100% 718/718 [30:52<00:00,  2.58s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 77/77 [01:54<00:00,  1.49s/it]\n",
            "                 all       1230       6912      0.476       0.52      0.454      0.179\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     15/29     12.3G   0.06187   0.02582  0.007507        59      1280: 100% 718/718 [30:49<00:00,  2.58s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 77/77 [01:56<00:00,  1.51s/it]\n",
            "                 all       1230       6912      0.546      0.474      0.471      0.189\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     16/29     12.3G   0.06098   0.02528  0.007017        44      1280: 100% 718/718 [30:59<00:00,  2.59s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 77/77 [01:55<00:00,  1.50s/it]\n",
            "                 all       1230       6912      0.529      0.506      0.478      0.191\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     17/29     12.3G   0.05975   0.02492  0.006715        45      1280: 100% 718/718 [30:54<00:00,  2.58s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 77/77 [01:58<00:00,  1.53s/it]\n",
            "                 all       1230       6912      0.576      0.495      0.481      0.197\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     18/29     12.3G   0.05955   0.02516  0.006405       108      1280: 100% 718/718 [31:12<00:00,  2.61s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 77/77 [01:55<00:00,  1.51s/it]\n",
            "                 all       1230       6912      0.578      0.503      0.492      0.199\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     19/29     12.3G   0.05773   0.02465   0.00619        42      1280: 100% 718/718 [30:40<00:00,  2.56s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 77/77 [01:56<00:00,  1.52s/it]\n",
            "                 all       1230       6912      0.609      0.506      0.504      0.204\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     20/29     12.3G   0.05741    0.0244  0.005777        39      1280: 100% 718/718 [30:56<00:00,  2.58s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 77/77 [01:55<00:00,  1.50s/it]\n",
            "                 all       1230       6912      0.627      0.496      0.517       0.21\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     21/29     12.3G   0.05684   0.02404  0.005473        65      1280: 100% 718/718 [30:57<00:00,  2.59s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 77/77 [01:54<00:00,  1.49s/it]\n",
            "                 all       1230       6912      0.628      0.505      0.509      0.206\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     22/29     12.3G   0.05584   0.02389  0.005054        58      1280: 100% 718/718 [30:49<00:00,  2.58s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 77/77 [01:51<00:00,  1.45s/it]\n",
            "                 all       1230       6912      0.614      0.519      0.511      0.212\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     23/29     12.3G   0.05533   0.02312   0.00473        44      1280: 100% 718/718 [31:22<00:00,  2.62s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 77/77 [01:58<00:00,  1.55s/it]\n",
            "                 all       1230       6912      0.627       0.52      0.517      0.212\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     24/29     12.3G   0.05466   0.02296  0.004675        94      1280: 100% 718/718 [31:32<00:00,  2.64s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 77/77 [02:00<00:00,  1.56s/it]\n",
            "                 all       1230       6912      0.608      0.522      0.514      0.214\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     25/29     12.3G   0.05388   0.02258  0.004412        74      1280: 100% 718/718 [32:03<00:00,  2.68s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 77/77 [01:58<00:00,  1.54s/it]\n",
            "                 all       1230       6912      0.627      0.528      0.519      0.216\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     26/29     12.3G   0.05327   0.02233  0.004071        40      1280: 100% 718/718 [32:04<00:00,  2.68s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 77/77 [02:01<00:00,  1.58s/it]\n",
            "                 all       1230       6912      0.637      0.532      0.531      0.219\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     27/29     12.3G   0.05282   0.02262  0.003926        52      1280: 100% 718/718 [32:14<00:00,  2.69s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 77/77 [01:59<00:00,  1.55s/it]\n",
            "                 all       1230       6912      0.653      0.525      0.526      0.215\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     28/29     12.3G   0.05256   0.02213  0.003787        48      1280: 100% 718/718 [32:05<00:00,  2.68s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 77/77 [01:59<00:00,  1.56s/it]\n",
            "                 all       1230       6912      0.625      0.531      0.519      0.213\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     29/29     12.3G   0.05206   0.02171  0.003818        70      1280: 100% 718/718 [32:06<00:00,  2.68s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 77/77 [02:00<00:00,  1.56s/it]\n",
            "                 all       1230       6912      0.646      0.534       0.53      0.221\n",
            "\n",
            "30 epochs completed in 16.847 hours.\n",
            "Optimizer stripped from runs/train/exp6/weights/last.pt, 71.6MB\n",
            "Optimizer stripped from runs/train/exp6/weights/best.pt, 71.6MB\n",
            "\n",
            "Validating runs/train/exp6/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model Summary: 396 layers, 35491344 parameters, 0 gradients, 51.5 GFLOPs\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 77/77 [01:59<00:00,  1.55s/it]\n",
            "                 all       1230       6912      0.646      0.532      0.529      0.221\n",
            "                 Car       1230       2270      0.781      0.692      0.742       0.43\n",
            "               Human       1230        486      0.757      0.488      0.563       0.23\n",
            "               Wagon       1230        987      0.803      0.714      0.753      0.454\n",
            "       FacingSwitchL       1230        120      0.651      0.567      0.566      0.226\n",
            "       FacingSwitchR       1230        113      0.718      0.653      0.619      0.238\n",
            "      FacingSwitchNV       1230        182      0.395      0.297      0.235     0.0778\n",
            "     TrailingSwitchL       1230        265      0.724      0.687      0.692      0.267\n",
            "     TrailingSwitchR       1230        151      0.638       0.55      0.543      0.179\n",
            "    TrailingSwitchNV       1230        438       0.39      0.308       0.22       0.06\n",
            "             SignalE       1230        741      0.632      0.412      0.424      0.136\n",
            "             SignalF       1230       1159      0.616      0.489      0.462      0.134\n",
            "Results saved to \u001b[1mruns/train/exp6\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fS95HSFmRVAF"
      },
      "source": [
        "<a id='part5'></a>\n",
        "<h1 align=\"center\">5. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eGrQsEsRdqb"
      },
      "source": [
        "–û—Ü–µ–Ω–∏–º –∫–∞—á–µ—Å—Ç–≤–æ –ª—É—á—à–∏—Ö –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–∏ (–∫–æ—Ç–æ—Ä—ã–µ —Å–æ—Ö—Ä–∞–Ω–∏–ª–∏—Å—å –ø–æ –ø—É—Ç–∏ `yolov5/runs/train/exp6/weights/best.pt`) –Ω–∞ –æ—Ç–ª–æ–∂–µ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ - `test dataset`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNzxUsbgQJgE",
        "outputId": "ac9255f6-5dff-4e79-b776-5806f7e5d7e3"
      },
      "source": [
        "!cd yolov5 && python val.py \\\n",
        "               --img 1280 \\\n",
        "               --data aitrain_dataset.yaml\\\n",
        "               --batch-size 16 \\\n",
        "               --task test \\\n",
        "               --weights runs/train/exp6/weights/best.pt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mdata=/content/yolov5/data/aitrain_dataset.yaml, weights=['runs/train/exp6/weights/best.pt'], batch_size=16, imgsz=1280, conf_thres=0.001, iou_thres=0.6, task=test, device=, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False\n",
            "YOLOv5 üöÄ v5.0-492-gb0ade48 torch 1.9.0+cu102 CUDA:0 (Tesla P100-PCIE-16GB, 16280.875MB)\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 396 layers, 35491344 parameters, 0 gradients, 51.5 GFLOPs\n",
            "\u001b[34m\u001b[1mtest: \u001b[0mScanning '../train_data/labels/test.cache' images and labels... 1231 found, 0 missing, 142 empty, 0 corrupted: 100% 1231/1231 [00:00<?, ?it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 77/77 [02:08<00:00,  1.67s/it]\n",
            "                 all       1231       6847       0.62      0.515      0.518      0.217\n",
            "                 Car       1231       2230      0.771       0.71      0.764      0.439\n",
            "               Human       1231        497      0.769      0.539      0.591      0.275\n",
            "               Wagon       1231        909      0.778      0.703      0.755      0.455\n",
            "       FacingSwitchL       1231        133       0.55      0.489      0.479      0.173\n",
            "       FacingSwitchR       1231        133      0.558      0.437      0.451      0.164\n",
            "      FacingSwitchNV       1231        223       0.45      0.327      0.281     0.0996\n",
            "     TrailingSwitchL       1231        303      0.696      0.686      0.663      0.227\n",
            "     TrailingSwitchR       1231        194      0.609      0.515      0.525      0.187\n",
            "    TrailingSwitchNV       1231        453      0.384      0.296      0.241     0.0703\n",
            "             SignalE       1231        768      0.638      0.454      0.461      0.155\n",
            "             SignalF       1231       1004      0.612      0.508      0.483      0.138\n",
            "Speed: 0.5ms pre-process, 22.0ms inference, 2.9ms NMS per image at shape (16, 3, 1280, 1280)\n",
            "Results saved to \u001b[1mruns/val/exp2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQP1bsclw6l3"
      },
      "source": [
        "<a id='part6'></a>\n",
        "<h1 align=\"center\">6. –û—Ü–µ–Ω–∏–≤–∞–Ω–∏–µ</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pj8xH0q-xBox"
      },
      "source": [
        "> **NOTE**: \n",
        "> - –õ—É—á—à–∏–µ –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏, –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –ø–æ–º–µ—Å—Ç–∏—Ç—å –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é `models/` –∏ –Ω–∞–∑–≤–∞—Ç—å `detection_model.pt`.\n",
        "> - –°–º–æ—Ç—Ä–∏—Ç–µ –ø—Ä–∏–º–µ—Ä –ø–æ—Å—ã–ª–∫–∏ `sample_submission.zip`.\n",
        "> - –ü—Ä–æ–≤–µ—Ä—è—é—â–∞—è —Å–∏—Å—Ç–µ–º–∞ –±—É–¥–µ—Ç –ø—Ä–∏–Ω–∏–º–∞—Ç—å –≤ –∫–∞—á–µ—Å—Ç–≤–µ –≤–∞—à–∏—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π detection_predictions.json —Ñ–æ—Ä–º–∞—Ç–∞ COCO, –ø–æ–¥—Ä–æ–±–Ω–µ–µ –ø–æ [—Å—Å—ã–ª–∫–µ](https://github.com/cocodataset/cocoapi/blob/master/results/instances_val2014_fakebbox100_results.json) –∏ –Ω–∞ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–º [—Å–∞–π—Ç–µ](https://cocodataset.org/#format-data).\n",
        "\n",
        "> - –§—É–Ω–∫—Ü–∏—è `detection.detection_predict.postprocess` - –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –Ω—É–∂–Ω–æ–≥–æ –≤–∏–¥–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.\n",
        "\n",
        "> - –§—É–Ω–∫—Ü–∏—è `evaluation.orig_box2coco.make_coco_detection_ann` - –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –±–æ–∫—Å—ã –¥–∞–Ω–Ω—ã–µ —É—á–∞—Å—Ç–Ω–∏–∫–∞–º –æ—Ç –æ—Ä–≥–∞–Ω–∏–∑–∞—Ç–æ—Ä–æ–≤ –∫ COCO Object Detection —Ñ–æ—Ä–º–∞—Ç—É."
      ]
    }
  ]
}
